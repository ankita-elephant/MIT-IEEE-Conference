from keras.metrics import MAPE #FOUR VARIABLES
import pandas as pd
import numpy as np
import math as m
from google.colab import files
#uploaded = files.upload()

SpartaScore = pd.read_csv('4var.csv')

TargetVariable=['Injury Risk']
Predictors=['Load', 'Explode', 'Drive', 'Mass']
#add variable
X=SpartaScore[Predictors].values
y=SpartaScore[TargetVariable].values

from sklearn.preprocessing import StandardScaler
PredictorScaler=StandardScaler()
TargetVariableScaler=StandardScaler()

PredictorScalerFit=PredictorScaler.fit(X)
TargetVariableScalerFit=TargetVariableScaler.fit(y)

X=PredictorScalerFit.transform(X)
y=TargetVariableScalerFit.transform(y)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
#import two, test with separate data set
print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

!pip install tensorflow
!pip install keras

from keras.models import Sequential
from keras.layers import Dense

model = Sequential() 
model.add(Dense(units=4, input_dim=4, kernel_initializer='normal', activation='relu'))
model.add(Dense(units=4, kernel_initializer='normal', activation='tanh'))
model.add(Dense(1, kernel_initializer='normal'))
model.compile(loss='mean_squared_error', optimizer= 'adam')
model.fit(X_train, y_train, batch_size=10, epochs = 30, verbose=1)

def FunctionFindBestParams (X_train, y_train, X_test, y_test):
  batch_size_list=[5, 10, 15, 20]
  epoch_list = [5, 10, 50, 100]

  import pandas as pd
  SearchResultsData=pd.DataFrame(columns=['Load t-score', 'Explode t-score', 'Drive t-score', 'Mass'])
  TrialNumber=0
  for batch_size_trial in batch_size_list:
    for epochs_trial in epoch_list:
      TrialNumber+=1
      model = Sequential ()
      model.add(Dense(units=4, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))
      model.add(Dense(units=4, kernel_initializer='normal', activation='relu')) #sigmoid for purely binary 
      model.add(Dense(1, kernel_initializer='normal'))
      model.compile(loss='mean_squared_error', optimizer='adam') #binary giving too high losses 
      model.fit(X_train, y_train, batch_size=batch_size_trial, epochs=epochs_trial, verbose=0)
      MAPE = np.mean(100*(np.abs(y_test-model.predict(X_test)/y_test)))
      print(TrialNumber, 'Parameters:', 'batch_size', batch_size_trial, '-', 'epochs:', epochs_trial, 'Accuracy:', 100-abs(MAPE))
      SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]], columns=['TrialNumber', 'Parameters', 'Accuracy'] )) 
  return (SearchResultsData)

ResultsData=FunctionFindBestParams(X_train, y_train, X_test, y_test)

%matplotlib inline
ResultsData.plot(x='Parameters', y='Accuracy', figsize=(15,4), kind='line')


model.fit(X_train, y_train, batch_size=15, epochs = 5, verbose=0)

Predictions=model.predict(X_test)

Predictions=TargetVariableScalerFit.inverse_transform(Predictions)

y_test_orig=TargetVariableScalerFit.inverse_transform(y_test)

Test_Data=PredictorScalerFit.inverse_transform(X_test)

TestingData=pd.DataFrame(data=Test_Data, columns=Predictors) 

TestingData['Injury Risk']=y_test_orig
TestingData['Predicted Injury Risk']=Predictions
TestingData.head()

for i in range(len(TestingData['Predicted Injury Risk'])):
  x = round(TestingData['Predicted Injury Risk'][i], 0)
  TestingData['Predicted Injury Risk'][i] = x
#\  #TestingData['Rounded'].append(x)

APE=abs(TestingData['Injury Risk']-TestingData['Predicted Injury Risk']) #avg raw error
TestingData['APE']=APE

print('The Accuracy of ANN Model IS:', np.mean(abs(APE)))
print("Testing Data")
print(TestingData)
np.around (Predictions)
